{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"real_time_pen_detection.ipynb","provenance":[],"collapsed_sections":["GGYW4HVrmwkP","znO60oLbnU58"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hbPoKBMzmlJr"},"source":["# Real time pen detection"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tTGIxuIu52Gy","executionInfo":{"status":"ok","timestamp":1635175014715,"user_tz":-120,"elapsed":17935,"user":{"displayName":"Francesco Pettini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09411479906065253176"}},"outputId":"e89fe5b7-bde5-45ba-debf-b452df736883"},"source":["# download Real-time_pen_detection repository\n","!git clone https://github.com/InnovationLab-Top/Real-time_pen_detection.git"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Real-time_pen_detection'...\n","remote: Enumerating objects: 81, done.\u001b[K\n","remote: Counting objects: 100% (81/81), done.\u001b[K\n","remote: Compressing objects: 100% (48/48), done.\u001b[K\n","remote: Total 81 (delta 8), reused 75 (delta 2), pack-reused 0\u001b[K\n","Unpacking objects: 100% (81/81), done.\n"]}]},{"cell_type":"code","metadata":{"id":"wmyH3HmY8lxK"},"source":["# download YOLOX\n","!git clone https://github.com/Megvii-BaseDetection/YOLOX.git\n","%cd /content/YOLOX\n","!pip3 install -U pip && pip3 install -r requirements.txt\n","!pip3 install -v -e .\n","%cd .."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LOykxK599ELa","executionInfo":{"status":"ok","timestamp":1635173861155,"user_tz":-120,"elapsed":520,"user":{"displayName":"Francesco Pettini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09411479906065253176"}}},"source":["# add num_classes in yolox_s.py for the training\n","with open('/content/YOLOX/exps/default/yolox_s.py', 'r') as file_src:\n","  lines = file_src.readlines()\n","with open('/content/YOLOX/exps/default/yolox_s.py', 'w+') as file_dst:\n","  lines[14] += '        self.num_classes = 1\\n'\n","  file_dst.write(\"\".join(lines))\n","\n","# change classes in /content/YOLOX/yolox/data/datasets/coco_classes.py\n","with open('/content/YOLOX/yolox/data/datasets/coco_classes.py', 'r') as file_src:\n","  lines = file_src.readlines()\n","with open('/content/YOLOX/yolox/data/datasets/coco_classes.py', 'w+') as file_dst:\n","  lines[3] = '\"\"\"\\n'\n","  lines[85] = ')\"\"\"\\n'\n","  lines[85] += 'COCO_CLASSES = (\"pen\",)\\n'  #change COCO_CLASSES with pen item (COMMA IS MANDATORY)\n","  file_dst.write(\"\".join(lines))"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wdvhWA8VlmG_"},"source":["## If you want to train the model\n","\n"]},{"cell_type":"code","metadata":{"id":"2RNqAS-2PZlx"},"source":["# download YOLO-to-COCO format converter\n","!git clone https://github.com/Taeyoung96/Yolo-to-COCO-format-converter.git\n","# May need to change in the future if Colab no longer uses CUDA 11.0\n","!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n","# DISCLAIMER: this installation requires a little bit time (5 minutes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ABzlIK6QWtW"},"source":["# install NVIDIA Apex\n","# DISCLAIMER: this installation requires a lot of time (about 10 minutes)\n","!git clone https://github.com/NVIDIA/apex\n","%cd apex\n","!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n","%cd .. "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mGcKDIrCV5TY"},"source":["# install PyCocoTools\n","!pip3 install cython; pip3 install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4CNHR8JtR9EU"},"source":["# create directories for COCO dataset format\n","!mkdir /content/YOLOX/datasets/COCO/\n","!mkdir /content/YOLOX/datasets/COCO/train2017/\n","!mkdir /content/YOLOX/datasets/COCO/annotations/\n","!mkdir /content/YOLOX/datasets/COCO/val2017/\n","!mkdir /content/YOLOX/datasets/COCO/unlabeled2017/\n","!mkdir /content/YOLOX/datasets/COCO/train2017/YOLO_annotations/\n","!mkdir /content/YOLOX/datasets/COCO/val2017/YOLO_annotations/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"14cUGI4OVmcM"},"source":["# copying images from Real-time_pen_detection repository to train2017 and val2017\n","! cp /content/Real-time_pen_detection/Images_resized/*  /content/YOLOX/datasets/COCO/train2017/\n","! cp /content/Real-time_pen_detection/Images_resized/*  /content/YOLOX/datasets/COCO/val2017/\n","# copying labels from Real-time_pen_detection repository to train2017 and val2017\n","! cp /content/Real-time_pen_detection/labels_txt/*  /content/YOLOX/datasets/COCO/train2017/YOLO_annotations/\n","! cp /content/Real-time_pen_detection/labels_txt/*  /content/YOLOX/datasets/COCO/val2017/YOLO_annotations/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"11djOECYs52y"},"source":["# change main.py in Yolo-to-COCO-format-converter\n","with open('/content/Yolo-to-COCO-format-converter/main.py', 'r') as file_src:\n","  lines = file_src.readlines()\n","with open('/content/Yolo-to-COCO-format-converter/main.py', 'w+') as file_dst:\n","  lines[17] = 'YOLO_DARKNET_SUB_DIR = \"YOLO_annotations\"\\n'  #folder in train/val2017 for annotations\n","  lines[18] = \"'''\\n\"\n","  lines[26] = \"'''\\n\"\n","  lines[27] = 'classes = [\"pen\"]\\n'  #change classes to pen\n","  lines[71] = '                int(label_line.split()[0])\\n'  #delete +1 to get category_id = 0\n","  lines[205] = '    output_path = \"/content/YOLOX/datasets/COCO/annotations/\" + output_name\\n'  #change output path\n","  lines[221] = '                \"id\": index,  \\n'  #delete +1 to get category_id = 0\n","  file_dst.write(\"\".join(lines))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MbTlqKp-Uv7a"},"source":["# convert Yolo to COCO format\n","!python /content/Yolo-to-COCO-format-converter/main.py --yolo-subdir --path /content/YOLOX/datasets/COCO/train2017 --output instances_train2017.json\n","!python /content/Yolo-to-COCO-format-converter/main.py --yolo-subdir --path /content/YOLOX/datasets/COCO/val2017 --output instances_val2017.json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m1-8kYfkGjVd"},"source":["# download pretrained weights on COCO dataset to initialize model weights\n","%cd /content/\n","!wget https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_s.pth\n","\n","PRETRAINED_PATH = '/content/yolox_s.pth'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DgPD6nbpxJdS"},"source":["# training\n","MODEL_PATH = '/content/YOLOX/exps/default/yolox_s.py'\n","TRAIN_PATH = '/content/YOLOX/tools/train.py'\n","\n","!python {TRAIN_PATH} -f {MODEL_PATH} -d 1 -b 8 --fp16 -o -c {PRETRAINED_PATH}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y57HV5OKoH5t"},"source":["# test on an image\n","DEMO_PATH = '/content/YOLOX/tools/demo.py'\n","TEST_IMAGE_PATH = '/content/Real-time_pen_detection/Test_frap.jpg'\n","WEIGHTS_PATH = '/content/YOLOX_outputs/yolox_s/latest_ckpt.pth'\n","\n","!python {DEMO_PATH} image -f {MODEL_PATH} -c {WEIGHTS_PATH} --path {TEST_IMAGE_PATH} --conf 0.4 --nms 0.45 --save_result --device gpu"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GGYW4HVrmwkP"},"source":["## If you want to use pretrained model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dpw6QnY69YzK","executionInfo":{"status":"ok","timestamp":1635173970199,"user_tz":-120,"elapsed":491,"user":{"displayName":"Francesco Pettini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09411479906065253176"}},"outputId":"0bc79470-9c3f-41b1-b01e-a06de8fd96e9"},"source":["import torch\n","%cd /content/YOLOX/"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/YOLOX\n"]}]},{"cell_type":"code","metadata":{"id":"gGEZ0DxzwBhq"},"source":["# loading model\n","model = torch.load('/content/Real-time_pen_detection/model.pth')\n","model.cuda()\n","model.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"znO60oLbnU58"},"source":["## Visualize real time pen detection"]},{"cell_type":"code","metadata":{"id":"ntAHfUXFByFe","executionInfo":{"status":"ok","timestamp":1635175182773,"user_tz":-120,"elapsed":488,"user":{"displayName":"Francesco Pettini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09411479906065253176"}}},"source":["# change original yolox demo.py file to modified one\n","!cp /content/Real-time_pen_detection/demo.py /content/YOLOX/tools/demo.py"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"-OC3mQ3hemlh","executionInfo":{"status":"ok","timestamp":1635174054567,"user_tz":-120,"elapsed":399,"user":{"displayName":"Francesco Pettini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09411479906065253176"}}},"source":["# import dependencies\n","from IPython.display import display, Javascript, Image\n","from google.colab.output import eval_js\n","from google.colab.patches import cv2_imshow\n","from base64 import b64decode, b64encode\n","import cv2\n","import numpy as np\n","import PIL\n","import io\n","import html\n","import time\n","import matplotlib.pyplot as plt\n","\n","# function to convert the JavaScript object into an OpenCV image\n","def js_to_image(js_reply):\n","  \"\"\"\n","  Params:\n","          js_reply: JavaScript object containing image from webcam\n","  Returns:\n","          img: OpenCV BGR image\n","  \"\"\"\n","  # decode base64 image\n","  image_bytes = b64decode(js_reply.split(',')[1])\n","  # convert bytes to numpy array\n","  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n","  # decode numpy array into OpenCV BGR image\n","  img = cv2.imdecode(jpg_as_np, flags=1)\n","\n","  return img\n","\n","# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n","def bbox_to_bytes(bbox_array):\n","  \"\"\"\n","  Params:\n","          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n","  Returns:\n","        bytes: Base64 image byte string\n","  \"\"\"\n","  # convert array into PIL image\n","  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n","  iobuf = io.BytesIO()\n","  # format bbox into png for return\n","  bbox_PIL.save(iobuf, format='png')\n","  # format return string\n","  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n","\n","  return bbox_bytes\n","\n","# JavaScript to properly create our live video stream using our webcam as input\n","def video_stream():\n","  js = Javascript('''\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","    \n","    var pendingResolve = null;\n","    var shutdown = false;\n","    \n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","    \n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","    \n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","      \n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","           \n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","      \n","      const instruction = document.createElement('div');\n","      instruction.innerHTML = \n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'When finished, click here or on the video to stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","      \n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","      \n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","      \n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","            \n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","      \n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","      \n","      return {'create': preShow - preCreate, \n","              'show': preCapture - preShow, \n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    ''')\n","\n","  display(js)\n","  \n","def video_frame(label, bbox):\n","  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n","  return data"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zgp_iHfXglPL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635175784887,"user_tz":-120,"elapsed":4145,"user":{"displayName":"Francesco Pettini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09411479906065253176"}},"outputId":"928374f7-78af-4f38-c32d-0c77a0791fc6"},"source":["# import functions from demo.py module\n","%cd /content/YOLOX/\n","from tools.demo import *\n","from yolox.data.datasets import COCO_CLASSES\n","from yolox.exp.build import *"],"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/YOLOX\n"]}]},{"cell_type":"code","metadata":{"id":"c5bn4I8AC92Z","executionInfo":{"status":"ok","timestamp":1635175787824,"user_tz":-120,"elapsed":395,"user":{"displayName":"Francesco Pettini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09411479906065253176"}}},"source":["# define the model predictor\n","predictor = Predictor(model, get_exp_by_file('/content/YOLOX/exps/default/yolox_s.py'), COCO_CLASSES, device = 'gpu')"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":868},"id":"koK4HtozgRCb","executionInfo":{"status":"error","timestamp":1635177154249,"user_tz":-120,"elapsed":94456,"user":{"displayName":"Francesco Pettini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09411479906065253176"}},"outputId":"f62bc3b6-12ea-4de3-eb25-476e763a2662"},"source":["# start streaming video from webcam\n","video_stream()\n","# label for video\n","label_html = 'Capturing...'\n","# initialze bounding box to empty\n","bbox = ''\n","count = 0 \n","detections = []\n","while True:\n","  js_reply = video_frame(label_html, bbox)\n","  if not js_reply:\n","      break\n","\n","  # convert JS response to OpenCV Image\n","  frame = js_to_image(js_reply[\"img\"])\n","  # create transparent overlay for bounding box\n","  bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n","\n","  # call our yolox_s on video frame\n","  outputs, img_info = predictor.inference_raw(frame)\n","  detections = predictor.visual_raw(outputs[0], img_info) #questa linea Ã¨ costata un oreo a FraV\n","\n","  # get labels and bboxes only if there's at least one detection (if no object is detected, detections will be a np.ndarray, else it will be a tuple of torch tensors)\n","  if type(detections) != np.ndarray:\n","    for i, _ in enumerate(detections[0]):\n","\n","      bbox = detections[0][i]\n","      label = \"pen\"\n","      confidence = detections[2][i]\n","\n","      left = int(bbox[0])\n","      top = int(bbox[1])\n","      right = int(bbox[2]) \n","      bottom = int(bbox[3])\n","\n","      if confidence > 0.5:\n","        bbox_array = cv2.rectangle(bbox_array, (left, top), (right, bottom), (255, 0, 0), 2)\n","        bbox_array = cv2.putText(bbox_array, \"{} [{:.2f}]\".format( label, float(confidence) ), \n","                                (left, top - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n","  bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n","  # convert overlay of bbox into bytes\n","  bbox_bytes = bbox_to_bytes(bbox_array)\n","  # update bbox so next frame gets new overlay\n","  bbox = bbox_bytes\n","  "],"execution_count":65,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","    \n","    var pendingResolve = null;\n","    var shutdown = false;\n","    \n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","    \n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","    \n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","      \n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","           \n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","      \n","      const instruction = document.createElement('div');\n","      instruction.innerHTML = \n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'When finished, click here or on the video to stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","      \n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","      \n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","      \n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","            \n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","      \n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","      \n","      return {'create': preShow - preCreate, \n","              'show': preCapture - preShow, \n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-65-13e92e7dd0cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mjs_reply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_html\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjs_reply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-00cba8fa7ebe>\u001b[0m in \u001b[0;36mvideo_frame\u001b[0;34m(label, bbox)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvideo_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stream_frame(\"{}\", \"{}\")'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zCacZdVZH5Ck","executionInfo":{"status":"ok","timestamp":1635176996366,"user_tz":-120,"elapsed":436,"user":{"displayName":"Francesco Pettini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09411479906065253176"}},"outputId":"6c8e31ef-e080-4f7b-d2e8-6762e16b4626"},"source":["print(((type(detections))))"],"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.ndarray'>\n"]}]},{"cell_type":"code","metadata":{"id":"y2tkLR5PhQ3c"},"source":["predictor = Predictor(model, get_exp_by_file(MODEL_PATH), COCO_CLASSES, device = 'gpu')"],"execution_count":null,"outputs":[]}]}